标题:为什么AI画不出章莹颖失踪案嫌犯画像？|章莹颖|嫌犯|AI
发布时间:2017-07-14 05:16
正文:中国警察林宇辉在章莹颖失踪案中，根据非常模糊且时间极短的监控视频画面，手绘出嫌犯的大致面貌，其相似程度震惊了美国军方。中国警察林宇辉的这一技能，相当于从马赛克中还原人像。这种“高级PS技能”应该是AI（人工智能）的强项，那AI能通过模糊监控还原出嫌犯画像吗？
我们先看一下中国警察林宇辉是如何做到的。他先将整个视频一帧一帧的看，从中挑出两张有嫌犯侧面的照片，然后将主体放大，通过侧面轮廓、隐约暴露出的脸，最终确定嫌犯的大致模样，然后画出来。这个过程可以分为两部分，前一部分是靠技术筛选出合适的照片，第二部分是靠经验和知识还原人像。
根据左侧模糊画面绘出的嫌犯画像
中国警察林宇辉
接下来我们看一下AI会怎么做呢？通常情况下AI会有两种解决方法，第一种方法是通过已有算法提高图像的清晰度，相当于把480P的视频转制成1080P，这种方法的弊端在于，虽然整体画面尺寸变大了，但细节会丢失非常严重，属于有损处理，对于后期辨认嫌犯并无太大帮助。而且这种方法也无法体现AI的智能一面。
第二种方法就是模拟人类的思维，也就是将人类的经验和知识通过智能算法实现。这个过程是非常复杂的，其中涉及到AI的很多方面。对于我们来说，虽然监控视频非常模糊，但我们可以判断车内有人，而且是男性，可能有络腮胡。但对于AI来说，这段监控视频实质就是一串数组。
从这段数组中，AI先判断出物体边缘得到局部图案，然后将局部图案组合形成简单形状，比如涉案车的车窗、人的胡子，然后将简单形状拼成物体的某部分，比如嫌犯侧脸，然后将所有部分组合在一起，AI才知道画面中有车辆、车内有人等信息，即使到了这一步，AI也只是知道车内有人而已。
ProjectOxford通过关键字生成的文字注释
介绍到这大家可能已经看出AI与我们的最大区别了，那就是意识。我们为什么判断监控视频中的人为男性呢，你可能会反问一句：这你还看不出来？对于AI来说，它需要一套逻辑，将“监控视频中的人为男性”的结果通过一套逻辑推理出来，这套逻辑就是AI的深度学习系统。
事实上，“什么是可以学习的”这个问题是AI反馈给我们的，因为AI的深度学习系统中的最重要部分——卷积神经网络，是模仿人类的视觉皮层体系结构而构建的，所以AI也有学不会的东西，即使耗费再多的CPU进行运算。AI要想分辨出监控视频中的人为男性，必须经过大量样本数据库的训练和学习。
人类的视觉皮层体系结构
这个学习的过程分为三种，而且这三种方法非常像一个人的成长过程。第一种是奖励式，比如AI如果推断出监控视频中车内是男性，我们给予奖励，如果没有推断出则无奖励。这种方式比较适合棋牌类游戏，学习过程实际是试错的过程。
第二种是开卷式，我们告诉AI，监控视频中车内为男性，然后AI通过对画面进行分析后，对类似情形进行判断。目前这是机器学习中使用最为普遍的方法；最后一种是意识式，让AI自己去了解世界，到底什么是车、怎么分辨男女等，就像人一样，成长的过程实质就是学习的过程。这种方法是AI学习最有效的方法，但目前实现不了。
综上我们可以猜到，让AI画出章莹颖案嫌犯画像的话，AI也要进行两步。第一步是选取视频中能够看清嫌犯侧脸的画面；第二步，通过之前开卷式学习，对所得画面与数据库中的画面进行比对，然后将最接近的部分组合在一起，构成嫌犯的画像。
AI在年龄识别等方面可用性出色
关键就在第二步上，AI所比对的画面很有可能都是侧脸照片，这些侧脸照片有没有正面照片就不得而知了，所以说AI可能会还原出相对清晰的侧脸图像，但正面图像很难还原出来，而且类似眼神、神态之类的，AI是无法准确还原的。从这个角度来看，目前AI还无法替代模拟画像专家。
观点总结：
以目前AI的技术水平，在有限规则内的领域会表现出色，比如下围棋的AlphaGo。一旦脱离规则或规律之后，以目前AI的学习方式，是很难做到优秀的。从模糊监控视频中画出嫌犯画像，实质相当于人脸识别，人类可以轻松判断车内嫌犯的部分属性，经过训练后可以画出非常神似的画像，但AI依然处在仅能够判断画面中有无人脸、数量多少的程度，还无法实现还原出神似的画像，AI技术依旧需要技术突破。
